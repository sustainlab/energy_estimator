{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the rolling estimates. The electricity readings of each home are used and a sliding window approach is applied to compute the average energy use estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as plticker\n",
    "\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "from IdealDataInterface import IdealDataInterface\n",
    "\n",
    "from config import TIME_FORMAT\n",
    "from config import SENSOR_DATA_FOLDER, CACHE_FOLDER, CPU_HIGH_MEMMORY, CPU_LOW_MEMMORY\n",
    "from config import EVALUATION_PERIOD, FFILL_LIMIT, SAMPLING_WINDOW, N_SAMPLES_ROLLING\n",
    "from config import ROLLING_WINDOW_WIDTH, ROLLING_WINDOW_STEP, SAMPLING_WINDOW_ROLLING, ROLLING_START_DATE\n",
    "from config import SAMPLING_MASK, IGNORE_HOMES\n",
    "\n",
    "from utils import treatment_control, load_mains\n",
    "\n",
    "from sampling import data_to_sample_array, sample_energy, compute_sample_sizes, compute_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run plotting styles\n",
    "%run -i '../src/sns_styles.py'\n",
    "\n",
    "cmap = sns.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 106 treatment and 107 control homes.\n"
     ]
    }
   ],
   "source": [
    "df_group = treatment_control()\n",
    "\n",
    "treatment_homes = df_group.loc[df_group['group'] == 'treatment', 'homeid']\n",
    "control_homes = df_group.loc[df_group['group'] == 'control', 'homeid']\n",
    "\n",
    "print('Found {} treatment and {} control homes.'.format(len(treatment_homes), len(control_homes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will create indices to the rolling window slices\n",
    "def rolling_window_indices(total_length, window_length, window_step):\n",
    "    \"\"\" Adapted from here: https://gist.github.com/alexlouden/e42f1d96982f7f005e62ebb737dcd987 \n",
    "    Note that in the referenced implementation the last window is not correctly specified. \"\"\"\n",
    "    # The \"trick\" is to create an array which holds the indices of each window in its rows.\n",
    "    # That is, each row is one \"window\". Vertically (along the rows) the first column will contain\n",
    "    # the first index of each respective window. The columns will then just need to \"count\" up\n",
    "    # to include the number of elements in the windows.\n",
    "    \n",
    "    # The start indices of each window, will be layed out across the rows\n",
    "    vert_idx_list = np.arange(0, total_length - window_length + 1, window_step)\n",
    "    \n",
    "    # Simply add the count for the number of elements in the window.\n",
    "    # This will be added to each row, i.e. marking the start and the subsequent\n",
    "    # indices along the columns.\n",
    "    hori_idx_list = np.arange(window_length)\n",
    "    \n",
    "    # Combine the above to create the array\n",
    "    A, B = np.meshgrid(hori_idx_list, vert_idx_list)\n",
    "    idx_array = A + B\n",
    "    \n",
    "    return idx_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_rolling(homeid, ROLLING_START_DATE, ROLLING_WINDOW_WIDTH, ROLLING_WINDOW_STEP, \n",
    "                     N_SAMPLES_ROLLING, SAMPLING_MASK, SAMPLING_WINDOW_ROLLING):\n",
    "    # Load the data\n",
    "    ts = load_mains(homeid)\n",
    "    \n",
    "    # Limit to the requested date range\n",
    "    ts = ts[ts.index >= ROLLING_START_DATE]\n",
    "    \n",
    "    # Divide the data into chunks of rolling windows\n",
    "    idx_array = rolling_window_indices(ts.shape[0], ROLLING_WINDOW_WIDTH, ROLLING_WINDOW_STEP)\n",
    "    \n",
    "    # Create the rolling windows. This will actually slice the time series and store each\n",
    "    # window in the list. This list is then passed to the multiprocessing.pool instance\n",
    "    # to compute the estimate for each window\n",
    "    windows = [ ts.iloc[idx_array[i,:]] for i in range(idx_array.shape[0]) ]\n",
    "    \n",
    "    # Compute the estimate per home using all cores\n",
    "    func = partial(compute_estimate, N=N_SAMPLES_ROLLING, SAMPLING_MASK=SAMPLING_MASK, SAMPLING_WINDOW=SAMPLING_WINDOW_ROLLING)\n",
    "\n",
    "    with Pool(processes=CPU_LOW_MEMMORY) as pool:\n",
    "        rolling_estimates = pool.map(func, windows)\n",
    "        \n",
    "    # Put everything into a DataFrame\n",
    "    df_result = pd.DataFrame(rolling_estimates)\n",
    "    \n",
    "    # The timestamp will be the left-most timestamp, i.e. the beginning of each roling window\n",
    "    df_result['time'] = ts.index[idx_array[:,0]]\n",
    "    \n",
    "    df_result['homeid'] = homeid\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will be skipping compution for homes already found in ../data/rolling_electricity_estimates\n"
     ]
    }
   ],
   "source": [
    "homeids = list(treatment_homes) + list(control_homes)\n",
    "\n",
    "homeids = set(homeids) - set(IGNORE_HOMES.keys())\n",
    "\n",
    "fpath = Path('../data/rolling_electricity_estimates/')\n",
    "if not fpath.is_dir():\n",
    "    fpath.mkdir()\n",
    "\n",
    "fname = lambda h: fpath / Path('homeid{}_estimated_rolling_electricty_use.csv'.format(h))\n",
    "\n",
    "print('Will be skipping compution for homes already found in {}'.format(fpath))\n",
    "\n",
    "for homeid in homeids:\n",
    "    # Compute the estimates but skip files that are already present\n",
    "    if fname(homeid).is_file():\n",
    "        continue\n",
    "    try:\n",
    "        df_estimates = estimate_rolling(homeid, ROLLING_START_DATE, ROLLING_WINDOW_WIDTH, ROLLING_WINDOW_STEP, \n",
    "                                        N_SAMPLES_ROLLING, SAMPLING_MASK, SAMPLING_WINDOW_ROLLING)\n",
    "    except:\n",
    "        print('Error in home {}.'.format(homeid))\n",
    "        continue\n",
    "\n",
    "    # Store to disk\n",
    "    df_estimates.to_csv(fname(homeid), sep='\\t', float_format='%.3f', date_format=TIME_FORMAT, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
